{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seafloor Spreading Bathymetry and Magnetic Anomalies\n",
    "\n",
    "**Our goals for today:**\n",
    "- Gain more experience loading, examining, and clearning data using ```pandas```.\n",
    "- Load marine geophysical data (bathymetry and marine magnetic anomalies) from two oceanic ridges. These are data types that underlie our understanding of seafloor spreading.\n",
    "- Plot bathymetry data and inspect to evaluate spreading rate.\n",
    "- Declare polynomial functions to detrend magnetic anomaly data.\n",
    "- Gain experience writing functions.\n",
    "- Plot marine magnetic anomaly data and calculate spreading rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell as it is to setup your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marine Geology, Bathymetry and Magnetic Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at marine magnetics and bathymetry data from two surveys, from the Mid-Atlantic Ridge and East Pacific Rise.\n",
    "\n",
    "The seafloor age model that you have been working with has been constructed from utilizing the record of Earth's flipping magnetic field that is preserved in the frozen lava/magma that constructed the oceanic crust.\n",
    "\n",
    "<img src=\"Figures/diagram-magnetic-reversals-ocean-ridge.jpg\" width=900>\n",
    "> Source: Enduring Resources for Earth Science Education, CC BY 4.0\n",
    "\n",
    "This video gives a very nice overview of the concepts of continental drift, sea floor spreading and the magnetic striping anomalies that we will examine in this notebook: https://youtu.be/JJEZ3Vizdww It is assigned as part of the out-of-class work this next week.\n",
    "\n",
    "First we'll load the Atlantic data (that can be accessed here: https://www.ncei.noaa.gov/maps/geophysics), and then we'll need to clean them up.\n",
    "\n",
    "The data file has the following columns:\n",
    "\n",
    "```\n",
    "['SURVEY_ID','TIMEZONE','DATE','TIME','LAT','LON','POS_TYPE','NAV_QUALCO','BAT_TTIME',\n",
    "'CORR_DEPTH','BAT_CPCO','BAT_TYPCO','BAT_QUALCO','MAG_TOT','MAG_TOT2','MAG_RES',\n",
    "'MAG_RESSEN','MAG_DICORR','MAG_SDEPTH','MAG_QUALCO','GRA_OBS','EOTVOS','FREEAIR',\n",
    "'GRA_QUALCO','LINEID','POINTID']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanc05mv_data_file = pd.read_table('./data_tracks/vanc05mv.m77t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this DataFrame a bit more compact, let's drop the columns that we will not be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic_data = vanc05mv_data_file.drop(columns=['SURVEY_ID','TIMEZONE','DATE','TIME','POS_TYPE','NAV_QUALCO',\n",
    "                                                 'BAT_TTIME','BAT_CPCO','BAT_TYPCO','BAT_QUALCO','MAG_TOT2','MAG_RES',\n",
    "                                                 'MAG_RESSEN','MAG_DICORR','MAG_SDEPTH','MAG_QUALCO','GRA_OBS','EOTVOS',\n",
    "                                                 'FREEAIR','GRA_QUALCO','LINEID','POINTID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.head()` function to inspect the `atlantic_data` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the dataframe using .head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.describe()` function applied to the DataFrame to examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use .describe() to examine the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some entries do not have either depth, magnetization  or both and instead in those fields `'NaN'` (not a number) is specified. The function ```np.isnan()``` identifies NaN entries.  Applying that function will give us a list of `True` and `False` (a boolean list). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.isnan(atlantic_data['CORR_DEPTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want the ```'NaN'``` values so we can used the complement (`~`) in the logical expression ```~np.isnan``` to find rows where there it is **not** ```'NaN'```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~np.isnan(atlantic_data['CORR_DEPTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same filtering using ```np.isfinite()``` which looks for values that are not infinity or not ```'NaN'```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isfinite(atlantic_data['CORR_DEPTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to have depth AND magnetic field measurements leaving only rows that have BOTH CORR_DEPTH and MAG_TOT specified. That is accomplished in the code cell below where we ask pandas to filter the DataFrame for values where `np.isfinite() = True` for both ```'CORR_DEPTH'``` and ```'MAG_TOT'```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic_data_clean = atlantic_data[np.isfinite(atlantic_data['CORR_DEPTH']) &  np.isfinite(atlantic_data['MAG_TOT'])];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.describe()` function applied to the DataFrame to examine the \"cleaned\" data. How many points are left now that we are requiring that there is both depth and magnetic data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our data!\n",
    "\n",
    "<font color=goldenrod>**_Code for you to write_**</font>\n",
    "\n",
    "**Plot atlantic_data on a map and make it have a linewidth of 2 and a color of orange**\n",
    "\n",
    "**Plot atlantic_data_clean on the same map and make it have a linewidth of 4 and a color of red**\n",
    "\n",
    "**Add a label to each plotted line ```label='description of data'``` so that they are keyed out in the legend.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,(15,15))\n",
    "ax = plt.axes(projection=ccrs.Robinson())\n",
    "ax.set_global()\n",
    "\n",
    "#ax.plot(ADD_CODE_HERE, transform=ccrs.PlateCarree())\n",
    "#ax.plot(ADD_CODE_HERE,transform=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to plot the cleaned data in profile with an x-axis of longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,(15,10))\n",
    "ax1=plt.subplot(2, 1, 1)\n",
    "#ax1.plot(..., ..., color='mediumblue')\n",
    "ax1.set_ylabel('Bathymetry, m')\n",
    "ax1.set_title('Mid-Atlantic Ridge')\n",
    "\n",
    "ax2=plt.subplot(2, 1, 2)\n",
    "#ax2.plot(..., ..., color='darkred')\n",
    "ax2.set_xlabel('Longitude, degrees')\n",
    "ax2.set_ylabel('Total magnetic field, nT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just analyze the portion of the survey from around the ridge, so from longitudes -24.0 to 0.0 degrees. Use Boolean indexing to pull out rows of `atlantic_data_clean` where `atlantic_data_clean['LON']` is between those values.\n",
    "\n",
    "<font color=goldenrod>**_Code for you to write_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atlantic_data_cropped = atlantic_data_clean[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a map of where our survey line was collected with a grid of seafloor bathymetry in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/MAR_track_map.png\" width=900>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,(15,10))\n",
    "ax1=plt.subplot(2, 1, 1)\n",
    "ax1.plot(atlantic_data_cropped['LON'],-1*atlantic_data_cropped['CORR_DEPTH'],color='mediumblue');\n",
    "ax1.set_ylabel('Bathymetry, m');\n",
    "ax1.set_title('Mid-Atlantic Ridge')\n",
    "\n",
    "ax2=plt.subplot(2, 1, 2)\n",
    "ax2.plot(atlantic_data_cropped['LON'],atlantic_data_cropped['MAG_TOT'],color='darkred');\n",
    "ax2.set_xlabel('Longitude, degrees');\n",
    "ax2.set_ylabel('Total magnetic field, nT');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the position of the ```LAT``` , ```LON``` magnetic track into a distance magnetic track referenced to the position of the spreading center. The position of the spreading center is assigned a distance of zero.  Since the data is already presented as a track we can simply find the distance of ```LAT``` , ```LON``` points along the track relative to the ridge position. To start, we create numpy arrays of lat, lon, bathymetry and magnetic intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data to numpy arrays\n",
    "atlantic_lat = np.array(atlantic_data_cropped['LAT'])\n",
    "atlantic_lon = np.array(atlantic_data_cropped['LON'])\n",
    "atlantic_bath = np.array(atlantic_data_cropped['CORR_DEPTH'])\n",
    "atlantic_mag = np.array(atlantic_data_cropped['MAG_TOT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the haversine function defined in the next cell to compute the distance between two points on a sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need a function to calculate distance between two points on a sphere. \n",
    "#Functions (or subroutines) are a good way to compartmentalize code for repeated operations\n",
    "#DO NOT EDIT THIS CELL BUT DO READ THROUGH IT TO UNDERSTAND CONSTRUCTION\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    A FUNCTION SHOULD HAVE A COMMENT BLOCK THAT STATES INPUT PARAMETERS AND \n",
    "    UNITS AND OUTPUT PARAMETERS AND UNITS\n",
    "    AS WELL AS DESCRIBE WHAT IT DOES\n",
    "    \n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees).\n",
    "\n",
    "    All args must be of equal length. i.e. floating point number, or arrays of numbers of equal length\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    lon1 : longitude of point 1 (in decimal degrees)\n",
    "    lat1 : latitude of point 1 (in decimal degrees)\n",
    "    lon2 : longitude of point 2 (in decimal degrees)\n",
    "    lat2 : latitude of point 2 (in decimal degrees)\n",
    "\n",
    "    Returns\n",
    "    ------------\n",
    "    distance : distance between point 1 and 2 in km\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    signfac=-dlon/np.abs(dlon)  #note the minus is because the difference of smaller number is positive\n",
    "    km = 6371 * c * signfac\n",
    "    return km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this ```haversine_distance()``` function to the distance between Berkeley (237.727, 37.8715) and your birthplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the ```haversine_distance()``` function to calculate distance from the ridge for all points in the profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the position of the ridge\n",
    "ridgelon = -10.07\n",
    "ridgelat = -48.05926\n",
    "\n",
    "#create lat2, lon2 arrays of the ridge position. \n",
    "#We do this to take advantage of the speed of vector arithmatic in python.\n",
    "lat2 = np.ones(len(atlantic_lat))*ridgelat\n",
    "lon2 = np.ones(len(atlantic_lat))*ridgelon\n",
    "atlantic_dist = haversine_distance(atlantic_lon,atlantic_lat,lon2,lat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the bathymetry and magnetic field data\n",
    "plt.figure(1,(15,10))\n",
    "ax1=plt.subplot(2, 1, 1)\n",
    "ax1.plot(atlantic_dist,-1*atlantic_bath,color='mediumblue')\n",
    "ax1.grid()\n",
    "ax1.set_title('Mid Atlantic Ridge')\n",
    "ax1.set_ylabel('Bathymentry, m')\n",
    "\n",
    "ax2=plt.subplot(2, 1, 2)\n",
    "ax2.plot(atlantic_dist,atlantic_mag,color='darkred')\n",
    "ax2.set_xlabel('Distance to Ridge, km')\n",
    "ax2.set_ylabel('Total magnetic field, nT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next lets load a data set for the East Pacific rise to compare with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seafloor depth, marine mag anom data\n",
    "# Source: https://maps.ngdc.noaa.gov/viewers/geophysics/\n",
    "#names=['SURVEY_ID','TIMEZONE','DATE','TIME','LAT','LON','POS_TYPE','NAV_QUALCO','BAT_TTIME','CORR_DEPTH','BAT_CPCO','BAT_TYPCO','BAT_QUALCO','MAG_TOT','MAG_TOT2','MAG_RES','MAG_RESSEN','MAG_DICORR','MAG_SDEPTH','MAG_QUALCO','GRA_OBS','EOTVOS','FREEAIR','GRA_QUALCO','LINEID','POINTID'])\n",
    "\n",
    "nbp9707_data_file=pd.read_table('data_tracks/nbp9707.m77t')\n",
    "pacific_data = nbp9707_data_file.drop(columns=['SURVEY_ID','TIMEZONE','DATE','TIME','POS_TYPE','NAV_QUALCO','BAT_TTIME','BAT_CPCO','BAT_TYPCO','BAT_QUALCO','MAG_TOT2','MAG_RES','MAG_RESSEN','MAG_DICORR','MAG_SDEPTH','MAG_QUALCO','GRA_OBS','EOTVOS','FREEAIR','GRA_QUALCO','LINEID','POINTID'])\n",
    "\n",
    "pacific_data_clean = pacific_data[~np.isnan(pacific_data['CORR_DEPTH']) &  ~np.isnan(pacific_data['MAG_TOT'])]; #use ~np.isnan to clear out rows were there are nans\n",
    "pacific_data_cropped = pacific_data_clean[(pacific_data_clean['LON']>-126.0) & (pacific_data_clean['LON']<-95.0)] # use Boolean indexing to select rows with Longitude -126 deg to -95 deg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a map of where our survey line was collected with a grid of seafloor bathymetry in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/EPR_track_map.png\" width=900>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1,(15,10))\n",
    "ax1=plt.subplot(2, 1, 1)\n",
    "#ax1.plot(pacific_data_cropped['LON'],-1*pacific_data_cropped['CORR_DEPTH'],color='blue')\n",
    "ax1.set_ylabel('Bathymetry, m')\n",
    "ax1.set_title('East Pacific Rise')\n",
    "\n",
    "ax2=plt.subplot(2, 1, 2)\n",
    "#ax2.plot(pacific_data_cropped['LON'],pacific_data_cropped['MAG_TOT'],color='blue')\n",
    "ax2.set_xlabel('Longitude, degrees')\n",
    "ax2.set_ylabel('Total magnetic field, nT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the position of the ridge\n",
    "ridgelon = -113.521\n",
    "tmp = np.array(pacific_data_cropped['LAT'][np.abs(pacific_data_cropped['LON'] - ridgelon) < 0.01])\n",
    "ridgelat = tmp[0]\n",
    "\n",
    "#Convert data to numpy arrays\n",
    "pacific_lat = np.array(pacific_data_cropped['LAT'])\n",
    "pacific_lon = np.array(pacific_data_cropped['LON'])\n",
    "pacific_bath = np.array(pacific_data_cropped['CORR_DEPTH'])\n",
    "pacific_mag = np.array(pacific_data_cropped['MAG_TOT'])\n",
    "\n",
    "#create lat2, lon2 arrays of the ridge position. We do this to take advantage of the speed of vector arithmatic in python.\n",
    "lat2 = np.ones(len(pacific_lat))*ridgelat\n",
    "lon2 = np.ones(len(pacific_lat))*ridgelon\n",
    "pacific_dist = haversine_distance(pacific_lon,pacific_lat,lon2,lat2)\n",
    "\n",
    "plt.figure(1,(15,10))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.plot(pacific_dist,-1*pacific_bath,color='mediumblue')\n",
    "ax1.set_title('South Pacific Ridge')\n",
    "ax1.set_ylabel('Bathymentry, m')\n",
    "ax1.grid()\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "ax2.plot(pacific_dist,pacific_mag,color='mediumblue')\n",
    "ax2.set_xlabel('Distance to Ridge, km')\n",
    "ax2.set_ylabel('Total magnetic field, nT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bathymetry\n",
    "\n",
    "Now let's compare the two ridges' bathymetry. \n",
    "\n",
    "Let's plot them together on one figure as subplots. Use $\\pm 1000$ km as the x-axis limits and -5000 to -1500 meters as the y-axis limits for both ridges. Use code that looks like this `ax1.set_xlim(xxx, xxx)` to set the x and y-axis limits.\n",
    "\n",
    "<font color=goldenrod>**_Code for you to write_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,(15,10))\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "#add code here\n",
    "ax1.set_xlabel('Distance to Ridge, km') # labels!\n",
    "ax1.set_ylabel('Bathymetry, m')\n",
    "ax1.set_title('East Pacific Rise')\n",
    "ax1.set_xlim(-1000,1000)\n",
    "#set yaxis limits\n",
    "ax1.grid()\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "#add code here\n",
    "ax2.set_xlabel('Distance to Ridge, km')\n",
    "ax2.set_ylabel('Bathymetry, m')\n",
    "ax2.set_title('Mid Atlantic Ridge')\n",
    "#set axes limits\n",
    "ax2.grid()\n",
    "\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/spreading_ridges.png\" width=900>\n",
    "> Source: Essentials of Geology (13th Edition) Lutgens, Tarbuck, and Tasa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion Questions:** What do you observe in the bathymetry? Do these ridges have a rift valley at the center? Is the slope steep or gentle? Is the bathymetry rough or smooth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the ridge bathymetry, which spreading center do you think is spreading faster the Atlantic or Pacific?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write code to remove polynomial fit and plot the East Pacific and Atlantic Magnetic Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are long wavelength trends in the magnetic data in addition to the anomalies we seek to understand associated with reversal. These include spatial variability in Earth's magnetic field that induces a field in the rocks on top of the ancient magnetization that is frozen into the rocks.\n",
    "\n",
    "We can approximate these trends with a linear, or perhaps higher order polynomial, in order to remove them. \n",
    "\n",
    "Let's start by fitting a linear model to the Pacific magnetic anomaly data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,(15,10))\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "ax2.plot(pacific_dist,pacific_mag,color='mediumblue')\n",
    "ax2.set_xlabel('Distance to Ridge, km')\n",
    "ax2.set_ylabel('Total magnetic field, nT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `np.polyfit()` to conduct a linear regression and fit a polynomial to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_values = pacific_dist\n",
    "mag_values = pacific_mag\n",
    "poly_order = 1\n",
    "\n",
    "np.polyfit(dist_values, mag_values, poly_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.polyfit()` returns the polynomial coefficients, highest power first. In this case the first value is the slope and the second value is the intercept.\n",
    "\n",
    "We can assign a variable `poly_coefficients` to be this array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_coefficients = np.polyfit(dist_values, mag_values, poly_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then access these coefficients in order with `poly_coefficients[0]` giving us the slope and `poly_coefficients[1]` giving us the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_coefficients[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_coefficients[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the higher order polynomial trends is a two step process where first we fit a model to the data, and then we remove the predictions of the model to reveal anomalies. We will use the numpy `np.polyfit()` to determine model coefficients (a, b, etc). \n",
    "\n",
    "$Y=a + bX + cX^2 + dX^3 + etc.$\n",
    "\n",
    "Then we will use numpy `np.poly1d()` to estimate the model for each independent variable to construct an array of model values to remove from the data. Let's write a function to do that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_detrend(dist_values, mag_values, poly_order):\n",
    "    \"\"\"\n",
    "    Function to fit a polynomial to data, and then remove the \n",
    "    fitted polynomial\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    dist_values : distance along profile in km\n",
    "    mag_values : magnetic data in nT\n",
    "    poly_order : integer indicating the order of the polynomial fit\n",
    "        0 (mean), 1 (line), 2 (parabola), 3, etc.\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    model (an array of modeled data), anomaly (an array of corrected data), rms (root mean square error)\n",
    "    \n",
    "    usage:\n",
    "    array1, array2, value=data_detrend(dist_values, mag_values, poly_order)\n",
    "    \"\"\"\n",
    "    \n",
    "    #np.polyfit() finds the coefficients for a polynomial of specified order\n",
    "    coefficients = np.polyfit(dist_values,mag_values,poly_order)\n",
    "    #np.poly1d() constructs a polynomial from the provided coefficients \n",
    "    p = np.poly1d(coefficients) \n",
    "    #we can calculate the values for that polynomial along the profile\n",
    "    model = p(dist_values) \n",
    "    #we can then subtract those values from the actual values leaving us with the anomaly\n",
    "    anomaly = mag_values - model\n",
    "    \n",
    "    #RMS error\n",
    "    rms = np.sqrt(np.mean(anomaly**2))\n",
    "    \n",
    "    return model, anomaly, rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a polynomial fit to the Mid-Atlantic data\n",
    "\n",
    "We want to compare the original data with the polynomial fit. We then want to test different values of the fit to find the best, and then remove the polynomial trend from the data.\n",
    "\n",
    "First, lets plot the data together with the polynomial fit\n",
    "\n",
    "<font color=goldenrod>**_Code for you to write_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the function\n",
    "#plot the model fit\n",
    "#find the simplest model that provides a good fit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a polynomial fit to the East Pacific Rise data\n",
    "\n",
    "Note you may or may not use different polynomial order for the two different data sets. Make sure to give the model and anomaly distinct variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the anomaly for the Mid-Atlantic Ridge\n",
    "\n",
    "Now plot the corrected data with the polynomial trend removed. Include a zero reference line: `plot([x1, x2],[y1, y2],color='black')`\n",
    "\n",
    "Consider distance ranges of -100 to 100 and -200 to 200. Consider putting in xticks every 10 km `ax1.set_xticks(np.arange(-200,200,10))`\n",
    "\n",
    "<font color=goldenrod>**_Code for you to write_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the anomaly \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the anomaly for the East Pacific Rise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/marine_mag_anom.png\" width=900>\n",
    "> Source: Fundamentals of Geophysics (2nd Edition) Lowrie, W."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in on the plot. \n",
    "\n",
    "Which wiggles can you match between lines and to the model profile due to the GPTS above? Can you pick the Bruhnes, Matuyama, Gauss, and Gilbert polarity chrons? \n",
    "\n",
    "What distance from the ridge does the Bruhnes-Matuyama reversal (which tells us an age of 776 kyr) occur at for both ridges? \n",
    "\n",
    "Zoom in on your plots and write down the distance between the ridge and the Bruhnes-Matuyama reversal for each ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that you can use to calculate the spreading rate in km/Myr using the distance from the ridge of the Bruhnes-Matuyama reversal. The function should take the distance to the reversal as input and return a spreading rate. An important piece of information is that the reversal occurred 776,000 years ago (Singer et al. 2019). Make sure that the function has a docstring and that the docstring indicates what units the calculated rate is in.\n",
    "\n",
    "You can find helpful information about functions here (part of your weekly reading): https://www.inferentialthinking.com/chapters/08/Functions_and_Tables.html\n",
    "\n",
    "<font color=goldenrod>**_Code for you to write_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_rate(dist, age):\n",
    "    \"\"\"\n",
    "    Function to compute the spreading rate\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    dist: distance to the ridge in km\n",
    "    age: age of the reversal in Myr\n",
    "    \n",
    "    output\n",
    "    ------\n",
    "    rate: spreading rate in km/Myr\n",
    "    \"\"\"\n",
    "    # write your code here\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your function to compute the spreading rate of the Atlantic and Pacific ridges. Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the marine magnetic anomalies, which spreading center do you think is spreading faster the Atlantic or Pacific? Is that consistent with your estimate from the bathymetry?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn in this notebook\n",
    "\n",
    "Save your completed notebook as html and upload to bcourses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e5f07e329e396bfef14d01cfb3c038f46bc2da10659a9022c958c3d0939fb8c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
